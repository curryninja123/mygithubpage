<html>
    <head>
        <title>Morals</title>
        <!--Import Google Icon Font-->
        <link href="http://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
        <!--Import materialize.css-->
        <link type="text/css" rel="stylesheet" href="css/materialize.min.css"  media="screen,projection"/>
        <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.0/build/pure-min.css" integrity="sha384-nn4HPE8lTHyVtfCBi5yW9d20FjT8BJwUXyWZT9InLYax14RDjBj46LmSztkmNP9w" crossorigin="anonymous">
        <!-- Import Cabin Font -->
        <link href="https://fonts.googleapis.com/css?family=Cabin" rel="stylesheet">
        <!-- Import Bootstrap -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
        <!--Let browser know website is optimized for mobile-->
        <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
        <link href="new.css" type = "text/css" rel="stylesheet">
    </head>
    <body>
        <div class="pure-g">
            <div class="pure-u-1-5"></div>
            <div class="pure-u-3-5">
                <h2 class="page-head">Morals</h2>
                <p class="body">
                    Here is a collection of morals and tips/tricks our section has come up with. This is intended to be a review of section as well as a homework helper and study resource for exams!
                </p>
                
                <h4 class="sub-head">6/18 Section 1A - Quantifiers and Logic</h4>
                <ul>
                    <li>DeMorgan's Extended Law - When negating quantified propositions, existential quantifiers flip to universal quantifiers and vise versa</li>
                    <li>Quantifier order matters!</li>
                    <li>Convert statements to easy English wherever possible.</li>
                    <li>Uniqueness implies that <b>for any</b> two solutions, they are equal.</li>
                </ul>
                <br>
                <h4 class="sub-head">6/19 Section 1B - Proof Techniques</h4>
                <ul>
                    <li>Parity (even vs odd) and order (less than, greater than) are good counter examples for proposition statements. In general, anything that divides a set into disjoint subsets that cover the whole set is a good test for a logical equivalence.</li>
                    <li>If you see "or" statements anywhere in an implication (especially on the right hand side), contraposition is probably a good idea.</li>
                    <li>If your proof seems on the right track but <i>very</i> handwavy or the proof seems difficult to do directly, try contradiction.</li>
                </ul>
                <br>
                <h4 class="sub-head">6/20 Section 1C - Induction</h4>
                <ul>
                    <li>For inductive proofs involving sums, it's usually a good idea to break off the last term.</li>
                    <li>When prooving the inductive step, try to separate the expression for the n=k case from the expression for the n=k+1 case algebraically.</li>
                    <li>If the inductive step depends on a term that is not the previous case (that is, something like n=k/2 or n=k-7 rather than n=k-1) then use strong induction.</li>
                </ul>
                <br>
                <h4 class="sub-head">6/21 Section 1D - Well Ordering Principle and Graphs</h4>
                <ul>
                    <li>Properties of trees are useful in proofs about cycles</li>
                    <li>Proofs involving the Well Ordering Principle usually follow from contradiction.</li>
                    <li>Whenever possible, try to prove statements about graphs directly using principles like the Handshake Lemma. These tend to be much more simple than inductive proofs. However, not all statements can be proved in this way.</li>
                </ul>
                <br>
                <h4 class="sub-head">6/25 Section 2A - Graph Theory</h4>
                <ul>
                    <li>The number of edges in a planar graph grow linearly with the number of vertices. That is, e = O(v).</li>
                    <li>For proofs about planarity, try to see if you can prove the statement directly with the 3v-6 edge upper bound before relying on techniques such as induction.</li>
                    <li>You can think of a dual of a planar graph as a shape whose corners are incident on all the faces of the original shape. For example, two rectangular pyramids with their bases touching is dual to a cube (imagine this shape inside a cube).</li>
                    <li>Duality has the interesting property that a dual of a dual of a graph is the same graph.</li>
                </ul>
                <br>
                <h4 class="sub-head">6/26 Section 2B - Graph Theory and Modular Arithmetic</h4>
                <ul>
                    <li>For proofs about coloring, induction might be worth a try. The idea is you ignore a vertex, inductive color the subgraph, add the vertex back, and pick a color for it.</li>
                    <li>Bipartite graphs can be defined as graphs that can be 2-colored (think of the left partition as one color and the right as another).</li>
                    <li>Systems of equations in mod work the same way as they do in the reals - you can add and subtract multiples of equations to each other.</li>
                    <li>The most general way to solve ax congruent to b mod m where a and m are relatively prime is to multiply both sides by the multiplicative inverse of a. This is the best way to get rid of an a on any side of a modular equation.</li>
                </ul>
                <br>
                <h4 class="sub-head">6/27 Section 2C - EGCD and Chinese Remainder Theorem</h4>
                <ul>
                    <li>There are multiple ways to perform the Extended Euclid GCD algorithm. The tabular way (see Piazza) is efficient, but in order to develop intuition, it's best to try the method on the discussion worksheet as well.</li>
                    <li>Intuitively, you can think of the GCD algorithm as folding a paper with integer lengths along a corner diagonal and then cutting out the resulting square until nothing is left - the last square is the GCD of the two numbers (see discussion 2C).</li>
                    <li>The Chinese Remainder Theorem interpolation problem can be thought of as constructing numbers which "raise" a particular modulo by 1 and keep the others at 0. If you are familiar with linear algebra, this is like creating basis vectors and then taking a linear combination of them to reconstruct the solution.</li>
                    <li>While CRT (and for that matter most modular arithmetic) problems tend to be hard to compuate but are straightforward to verify. Make sure you do this when going through an exam! </li>
                </ul>
                <br>
                <h4 class="sub-head">6/28 Section 2D - RSA</h4>
                <ul>
                    <li>In order to get rid of a term x on one side of a modular equation, multiply both sides by the inverse of x. Conversely, to get rid of the inverse of x, multiply both sides by x. Intuitively, this works the same way as it does in the real numbers.</li>
                    <li>Knowing the private keys in RSA is essentially equivalent to being able to factor the numbers.</li>
                    <li>The Chinese Remainder Theorem states that any system of k congruences of the form x is congruent to a<sub>i</sub> mod m<sub>i</sub> for relatively prime m<sub>i</sub> has a unique solution mod m<sub>1</sub>...m<sub>k</sub> (the product of the moduli). This is useful when solving for the value of a number od a product of primes - break it down into a smaller system of congruences and reconstruct the solution using the Chinese Remainder Theorem method shown earlier.</li>
                    <li>Most proofs for the RSA algorithm essentially follow the same format, but certain parts are different based on the variety in the scheme. For example, in the three-prime RSA scheme, we made the same argument as in the two-prime case, defining our value of N and private key modulo as natural extensions (see discussion 2d). It is worth understanding the purpose of each step and why we make it in order to extend this proof to different schemes.</li>
                </ul>
                <br>
                <h4 class="sub-head">7/2 Section 3A - Polynomials</h4>
                <ul>
                    <li>The Galois Field (GF) basically means you are considering the polynomial mod p for some prime p. As we will see later, it matters that p is prime for some important properties to hold. This means that the coefficients are reduced mod p. 7x will go to 2x mod 5.</li>
                    <li>A polynomial of degree d will have exactly d complex roots, some of which may be real. It makes sense intuitively that at most d roots will occur on the reals, because a nonzero polynomial of degree d may be equal to zero at at most d points (if it was equal at d+1 points it would just be the zero polynomial).</li>
                    <li>We know that imaginary roots will always be paired up, so there will be an even number of them.</li>
                    <li>Intuition about the number of roots is very different in GF(p) - make sure to think of counterexamples using FLT and similar theorems.</li>
                    <li>A polynomial of degree greater than or equal to p cannot exist in GF(p). This makes sense intuitively because there are at most p possible points that the polynomial can go through, and that specifies a polynomial of degree p-1. Mathematically, you can use FLT (try this out on your own) to reduce the degree of a polynomial in GF(p).</li>
                </ul>
                <br>
                <h4 class="sub-head">7/3 Section 3B - Error Correcting Codes</h4>
                <ul>
                    <li>Secret sharing and error correcting are two different motivations utilizing a similar concept - you can use some points to encode a polynomial and use that polynomial to generate more similar information. In the former case, you split up that information whereas in the latter case you send extra information to make up for lost or corrupted information.</li>
                    <li>For erased information, you add an extra amount of information equal to the number of packets lost. The intuition is harder for corrupted packets - you have to go through the derivation of the Berlekamp-Welch algorithm</li>
                    <li>r<sub>i</sub> is the <i>receieved</i> information not the <i>sent</i> information</li>.
                    <li>The key observation in Berlekamp-Welch is that Q(i) = P(i)E(i) = r<sub>i</sub> E(i)in the case where there is an error (because both sides are 0) and in the case where there isn't an error (because the received message r<sub>i</sub> is the same as the sent message P(i)</li>
                </ul>
                <br>
                <h4 class="sub-head">7/5 Section 3D - Countability</h4>
                <ul>
                    <li>If a set A "seems" smaller than another countable set B (for example, there is an injection from A to B) then A is also countable.</li>
                    <li>Likewise, if a set A "seems" larger than another uncountable set B, then A is also uncountable.</li>
                    <li>Diagonalization proofs all follow a similar argument. You assume countability for the sake of contradiction and suppose the existence of some special element x created by changing some aspects of other elements on the list with the idea that x will appear at the n-th position but the n-th position of x's representation will result in a contradiction.</li>
                    <li>Cartesian Product of countable sets is countable.</li>
                </ul>
                <br>
                <h4 class="sub-head">7/9 Section 4A - Computability</h4>
                <ul>
                    <li>Computability problems follow a similar form - reduce a problem <i>from</i> (not to) the halting problem or another uncomputable problem like TestHelloWorld to show that it is uncomputable.</li>
                    <li>In reductions, use the program you are assuming does not exist as the black box, <b>not the other way around</b>.</li>
                    <li>Computer programs are strings and are therefore countable. Functions are, in general, uncountable</li>
                </ul>
                <br>
                <h4 class="sub-head">7/10 Section 4B - Counting</h4>
                <ul>
                    <li>There are multiple ways to count things. As long as your intuition has been shown to be correct, do whatever you're most comfortable with!</li>
                    <li>Bitstrings of length n can be thought of as analogous to subsets from a set of size n. We can derive the combinatorial symbol in this way. Furthermore, since there are two choices for each element to create a subset (either the element is in the subset or not), the number of total subsets is 2<sup>n</sup>.</li>
                    <li>Stars and Bars is essentially an anagram problem using a letter for each object and divider.</li>
                    <li>Keep a running list of how to count in different situations and always relate new problems to ones you've solved before.</li>
                    <li>n choose k is the same as n choose n - k. Instead of choosing the n elements in a subset, we can exclude n - k and use the remaining k.</li>
                </ul>
                <br>
                <h4 class="sub-head">7/11 Section 4C - Discrete Probability</h4>
                <ul>
                    <li>For uniform probability, you can count the number of successful events and divide it by the number of total events.</li>
                    <li>Take care about counting number of arrangements in discrete probability. For the book problem in discussion, you have to treat the objects as distinct, because if you just count all the math books as the same, that disregards the fact that there are 120 ways to rearrange them. The safest bet is to think in terms of events.</li>
                    <li>Inclusion-Exclusion makes sense when you think of drawing Venn Diagrams. See <a href="https://en.wikipedia.org/wiki/Inclusion–exclusion_principle#/media/File:Inclusion-exclusion-3sets.png">this picture</a> for such an example.</li>
                    <li>It's easier to lower bound the minimum and upper bound the maximum of a group of random variables. If you lower bound the minimum, then you have that <i>all</i> of the variables are greater than that bound and if you upper bound the maximum then you have that <i>all</i> of the variables are less than that bound. To convert between upper and lower bounds, use the complement.</li>
                </ul>
                <br>
                <h4 class="sub-head">7/12 Section 4D - Conditional Probability</h4>
                <ul>
                    <li>The definitions of independence are all equal and can be derived using the definition of conditional probability.</li>
                    <li>We can think of symmetry like this - if we <i>don't know</i> the result of the first trial and want to consider the second trial, it is effectively the same as performing both trials simultaneously and arbitrarily deeming one the first and the other the second.</li>
                    <li>When calculating the probability breaks down into cases, the total probability rule is the way to go.</li>
                </ul>
                <br>
                <h4 class="sub-head">7/16 Section 5A - Bayes' Rule</h4>
                <ul>
                    <li>Bayes' rule can also be derived using the definition of conditional probability.</li>
                    <li>Bayes' rule is extremely useful for flipping conditionals.</li>
                    <li>Mutual independence is stronger than pairwise independence (or k-wise independence for any k).</li>
                    <li>(k+1)-wise independence is stronger than k-wise independence for any k.</li>
                </ul>
                <br>
                <h4 class="sub-head">7/17 Section 5B - Important Distributions</h4>
                <ul>
                    <li>If given a number of independent of trials and probability of any individual trial succeeding, it is binomial.</li>
                    <li>If counting the number of trials before a success, it is geometric.</li>
                    <li>Be careful how you define "success" for a particular problem.</li>
                    <li>If an event A implies the occurence of an event B and vice versa, then both events are equal (think of events like sets and then consider set equality conditions in terms of subsets).</li>
                    <li>If given a mean number of successes over a period of time, it is Poisson.</li>
                    <li>The sum of Poissons is Poisson in an intuitive way - the parameters add.</li>
                </ul>
                <br>
                <h4 class="sub-head">7/18 Section 5C - Expectation</h4>
                <ul>
                    <li>Expectation is essentially a weighted average.</li>
                    <li>Indicator random variables are useful for "counting" things, such as number of empty bins. They are more useful in some applications than others.</li>
                    <li>Linearity of expectation is a very powerful and robust tool that does not require independence. It is useful in almost every expectation calculation problem.</li>
                    <li>Any (positive) power of an indicator r.v. is just the indicator itself because 0 and 1 to any power are just 0 and 1 themselves.</li>
                    <li>The expectation of an indicator r.v. is the probability of the corresponding "indicated" event.</li>
                </ul>
                <br>
                <h4 class="sub-head">7/19 Section 5D - Variance</h4>
                <ul>
                    <li>Breaking down into indicators is also useful for variance calculations. There is one common technique: (X<sub>1</sub> + ... + X<sub>n</sub>)<sup>2</sup> is the sum of the squares of each individual indicator X<sub>i</sub> plus the pairwise product of any two different indicators in different orders. That is, all terms X<sub>i</sub>X<sub>j</sub> and X<sub>j</sub>X<sub>i</sub> (you have to inlcude both).</li>
                    <li>The next step is to use linearity of expectation and the properties of indicators.</li>
                    <li>The product of two indicators is an indicator for the event that both events indicated by the indicators happen.</li>
                    <li>In most indicator-based expectation and variance problems, the main source of difference comes from calculating the expectation of indicators and the expectation of the product of indicators.</li>
                    <li>To move from a distribution of Y conditioned on X to an unconditioned distribution on Y, apply the law of total probability by summing over all possible values of X (see problem 3 for an example).</li>
                </ul>
                <br>
                <h4 class="sub-head">7/23 Section 6A - Covariance</h4>
                <ul>
                    <li>Independence implies uncorrelation but not necessarily the other way around.</li>
                    <li>The basic idea behind random variables that are dependent but uncorrelated is that they could be related in a <i>nonlinear</i> way. The example given in class was that |X + Y| = 1, XY = 0, and for a fixed X, we have that Y could be one of two possible answers with equal probability.</li>
                    <li>The variance of a random variable is the covariance of a random variable with itself.</li>
                    <li>The tail sum formula, intuitively, comes from breaking a nonnegative random variable X down to indicators Y<sub>i</sub> for positive integers i corresponding to the event that X is at least i and then applying linearity of expectation.</li>
                </ul>
                <br>
                <h4 class="sub-head">7/24 Section 6B - Conditional Expectation and Coupon Collector</h4>
                <ul>
                    <li>The geometric distribution is the <i>only</i> discrete distribution with the memoryless property.</li>
                    <li>The expectation of a random variable is not a random variable, but the expectation of a random variable <i>conditioned</i> on another random variable is a random variable.</li>
                    <li>General coupon collectors follow a similar pattern. Denote X<sub>i</sub> as the time to collect the i+1-th coupon starting with i already collected coupons and then take the sum of the X<sub>i</sub> from 0 to n-1, using linearity of expectation.</li>
                    <li>The main separating factor for these problems comes from the actual distribution of each of the X<sub>i</sub>, which usually tend to be geometric.</li>
                </ul>
                <br>
                <h4 class="sub-head">7/25 Section 6C - Continuous Probability I</h4>
                No morals today, but here are the 5 steps to solve most continuous probability problems.
                <ol>
                    <li>Draw the feasible region. That is, over the plane of your random variables, sketch the region of possible values for the variables.</li>
                    <li>Draw your constraints. That is, shade in the part of the feasible region that you'd want to consider. For example, if Y > X, shade in the region above the line Y = X.</li>
                    <li>Consider splitting into cases. This is useful for absolute values. When integrating |Y - X| in an expectation, you could split into a region where |Y - X| = Y - X and one where it equals X - Y. These two functions are easier to integrate over.</li>
                    <li>Calculate the pdfs of the random variables. Sometimes it might be easier to calculate the cdf (or the complement of the cdf) and then take the derivative.</li>
                    <li>Choose an order of integration (see my calculus notes on Piazza) and integrate the pdfs over the region.</li>
                </ol>
                <br>
                <h4 class="sub-head">7/26 Section 6D - Continuous Probability II</h4>
                <ul>
                    <li>Sum of independent Gaussians is a Gaussian.</li>
                    <li>The marginal distribution just means the distribution of a given variable (derived from the joint distribution by summing/integrating over the other variables).</li>
                </ul>
                <br>
                <h4 class="sub-head">7/30 Section 7A - Markov's and Chebyshev's Inequalities</h4>
                <ul>
                    <li>To apply Chebyshev's inequality, one has to make the event symmetric about a center. For example, if a random variable X has mean 2, the event X > 6 can be upper bounded by the event X > 6 or  -2 > X and then Chebyshev's inequality can be applied. </li>
                    <li>In general, Chebyshev's inequality gives a tighter bound than Markov's inequality and does not require the random variable to be positively valued.</li>
                    <li>If the number of samples goes up, the variance of the average of the samples tends to go down. This is useful in constructing confidence intervals.</li>
                    <li>Confidence intervals have a few main properties: center, width (also called error), variance, and confidence. Most problems involve manipulating a few of these variables to figure out the others and the manipulations almost always involve Chebyshev's inequality or a similar form.</li>
                    <li>If figuring out the fewest number of samples needed to attain a certain confidence, one should round up to the nearest integer (think about why).</li>
                </ul>
                <br>
                <h4 class="sub-head">7/31 Section 7B - Markov Chains I</h4>
                No morals today, but quite a few tomorrow! Mostly just vocabulary and terminology for this section, so I'd recommend looking at the notes.
                <br>
                <h4 class="sub-head">8/1 Section 7C - Markov Chains II</h4>
                <ul>
                    <li>Irreducibility means that between any two nodes a and b, there is a directed path from a to b and from b to a.</li>
                    <li>Aperiodicity requires all nodes to have d(i) = 1. That is, there must be at least walks to get from a node back to itself whose lengths are coprime. One simply has to demonstrate two such paths to prove the aperiodicity of a node.</li>
                    <li>If a Markov chain is irreducible and one node has d(i) = 1, then all nodes have d(i) = 1</li>
                    <li>You can think of hitting times as a conditional/total expectation problem - what's the expected time to reach a destination if I take this as my next step? It's 1 plus the expected time from the next node to the destination.</li>
                </ul>
                <br>
                <h4 class="sub-head">8/2 Section 7D - Markov Chains III</h4>
                <ul>
                    <li>The invariant and stationary distributions are the same thing.</li>
                    <li>In addition to the equation πP = π, you need to add the constraint that the sum of the π(i) = 1 in order to solve for the invariant distribution.</li>
                    <li>Every Markov chain has at least one invariant distribution. If the Markov chain is irreducible, the invariant distribution is unique. If, furthermore, the Markov chain is aperiodic (as well as irreducible) every initial distribution <i>converges</i> to the invariant distribution (don't worry about the exact idea here, just know it gets closer and closer to the invariant).</li>
                    <li>The invariant distribution is the distribution of the long-term fraction of the time that the chain is in a given state.</li>
                </ul>
                <br>
                <a class="bodylink" href="teaching.html">Back to teaching home page.</a>
                <br>
            </div>
            <div class="pure-u-1-5"></div>
        </div>
        <br><br>
    </body>
</html>